{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CBOW Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the corpus vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful,</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast, and beans</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick anf the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Document  \\\n",
       "0                                       The sky is blue and beautiful,   \n",
       "1                                    Love this blue and beautiful sky!   \n",
       "2                         The quick brown fox jumps over the lazy dog.   \n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast, and beans   \n",
       "4                          I love green eggs, ham, sausages and bacon!   \n",
       "5                     The brown fox is quick anf the blue dog is lazy!   \n",
       "6             The sky is very blue and the sky is very beautiful today   \n",
       "7                          The dog is lazy but the brown fox is quick!   \n",
       "\n",
       "  Category  \n",
       "0  weather  \n",
       "1  weather  \n",
       "2  animals  \n",
       "3     food  \n",
       "4     food  \n",
       "5  animals  \n",
       "6  weather  \n",
       "7  animals  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['The sky is blue and beautiful,',\n",
    "         'Love this blue and beautiful sky!',\n",
    "         'The quick brown fox jumps over the lazy dog.',\n",
    "         \"A king's breakfast has sausages, ham, bacon, eggs, toast, and beans\",\n",
    "         'I love green eggs, ham, sausages and bacon!',\n",
    "         'The brown fox is quick anf the blue dog is lazy!',\n",
    "         'The sky is very blue and the sky is very beautiful today',\n",
    "         'The dog is lazy but the brown fox is quick!']\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
    "\n",
    "corpus = np.array(corpus)\n",
    "corpus_df = pd.DataFrame({'Document' : corpus,\n",
    "                         'Category' : labels})\n",
    "corpus_df = corpus_df[['Document', 'Category']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    \n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    \n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sky blue beautiful', 'love blue beautiful sky',\n",
       "       'quick brown fox jumps lazy dog',\n",
       "       'kings breakfast sausages ham bacon eggs toast beans',\n",
       "       'love green eggs ham sausages bacon',\n",
       "       'brown fox quick anf blue dog lazy',\n",
       "       'sky blue sky beautiful today', 'dog lazy brown fox quick'],\n",
       "      dtype='<U51')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus = normalize_corpus(corpus)\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible = gutenberg.sents('bible-kjv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_terms = punctuation + '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 30103\n",
      "\n",
      "Sample line: ['1', ':', '6', 'And', 'God', 'said', ',', 'Let', 'there', 'be', 'a', 'firmament', 'in', 'the', 'midst', 'of', 'the', 'waters', ',', 'and', 'let', 'it', 'divide', 'the', 'waters', 'from', 'the', 'waters', '.']\n",
      "\n",
      "Processed line: god said let firmament midst waters let divide waters waters\n"
     ]
    }
   ],
   "source": [
    "norm_bible = [[word.lower() for word in sent if word not in remove_terms] for sent in bible]\n",
    "norm_bible = [' '.join(tok_sent) for tok_sent in norm_bible]\n",
    "norm_bible = filter(None, normalize_corpus(norm_bible))\n",
    "norm_bible = [tok_sent for tok_sent in norm_bible if len(tok_sent.split()) > 2]\n",
    "\n",
    "print('Total lines:', len(bible))\n",
    "print('\\nSample line:', bible[10])\n",
    "print('\\nProcessed line:', norm_bible[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Continuous Bag of Words (CBOW) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the corpus vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(norm_bible)\n",
    "word2id = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 12425\n",
      "Vocabulary Sample: [('shall', 1), ('unto', 2), ('lord', 3), ('thou', 4), ('thy', 5), ('god', 6), ('ye', 7), ('said', 8), ('thee', 9), ('upon', 10)]\n"
     ]
    }
   ],
   "source": [
    "# build vocabulary of unique words\n",
    "word2id['PAD'] = 0\n",
    "id2word = {v : k for k, v in word2id.items()}\n",
    "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_bible]\n",
    "\n",
    "vocab_size = len(word2id)\n",
    "embed_size = 100\n",
    "window_size = 2 # context window size\n",
    "\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a CBOW (contex, target) generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
    "    context_length = window_size * 2\n",
    "    for words in corpus:\n",
    "        sentence_length = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            context_words = []\n",
    "            label_word = []\n",
    "            start = index - window_size\n",
    "            end = index + window_size + 1\n",
    "            \n",
    "            context_words.append([words[i]\n",
    "                                for i in range(start, end)\n",
    "                                if 0 <= i < sentence_length\n",
    "                                 and i != index])\n",
    "            label_word.append(word)\n",
    "            \n",
    "            x = sequence.pad_sequences(context_words, maxlen = context_length)\n",
    "            y = np_utils.to_categorical(label_word, vocab_size)\n",
    "            yield(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context (X): ['old', 'testament', 'james', 'bible'] -> Target (Y): king\n",
      "Context (X): ['first', 'book', 'called', 'genesis'] -> Target (Y): moses\n",
      "Context (X): ['beginning', 'god', 'heaven', 'earth'] -> Target (Y): created\n",
      "Context (X): ['earth', 'without', 'void', 'darkness'] -> Target (Y): form\n",
      "Context (X): ['without', 'form', 'darkness', 'upon'] -> Target (Y): void\n",
      "Context (X): ['form', 'void', 'upon', 'face'] -> Target (Y): darkness\n",
      "Context (X): ['void', 'darkness', 'face', 'deep'] -> Target (Y): upon\n",
      "Context (X): ['spirit', 'god', 'upon', 'face'] -> Target (Y): moved\n",
      "Context (X): ['god', 'moved', 'face', 'waters'] -> Target (Y): upon\n",
      "Context (X): ['god', 'said', 'light', 'light'] -> Target (Y): let\n",
      "Context (X): ['god', 'saw', 'good', 'god'] -> Target (Y): light\n"
     ]
    }
   ],
   "source": [
    "# Test this out for some examples\n",
    "\n",
    "i = 0\n",
    "for x, y in generate_context_word_pairs(corpus = wids, window_size = window_size, vocab_size = vocab_size):\n",
    "    if 0 not in x[0]:\n",
    "        print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
    "        \n",
    "        if i == 10:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulld CBOW architecture\n",
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim = vocab_size, output_dim = embed_size, input_length = window_size * 2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis = 1), output_shape = (embed_size,)))\n",
    "cbow.add(Dense(vocab_size, activation = 'softmax'))\n",
    "cbow.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 100)            1242500   \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12425)             1254925   \n",
      "=================================================================\n",
      "Total params: 2,497,425\n",
      "Trainable params: 2,497,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"405pt\" viewBox=\"0.00 0.00 242.00 304.00\" width=\"323pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 238,-300 238,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2030821835720 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2030821835720</title>\n",
       "<polygon fill=\"none\" points=\"15.5,-249.5 15.5,-295.5 218.5,-295.5 218.5,-249.5 15.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"54\" y=\"-268.8\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"92.5,-249.5 92.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"92.5,-272.5 148.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"148.5,-249.5 148.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183.5\" y=\"-280.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"148.5,-272.5 218.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183.5\" y=\"-257.3\">(None, 4)</text>\n",
       "</g>\n",
       "<!-- 2030830022600 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2030830022600</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 234,-212.5 234,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"40\" y=\"-185.8\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"80,-166.5 80,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"80,-189.5 136,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"136,-166.5 136,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-197.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"136,-189.5 234,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-174.3\">(None, 4, 100)</text>\n",
       "</g>\n",
       "<!-- 2030821835720&#45;&gt;2030830022600 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2030821835720-&gt;2030830022600</title>\n",
       "<path d=\"M117,-249.366C117,-241.152 117,-231.658 117,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"120.5,-222.607 117,-212.607 113.5,-222.607 120.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030821837384 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2030821837384</title>\n",
       "<polygon fill=\"none\" points=\"9,-83.5 9,-129.5 225,-129.5 225,-83.5 9,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"40\" y=\"-102.8\">Lambda</text>\n",
       "<polyline fill=\"none\" points=\"71,-83.5 71,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"71,-106.5 127,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"127,-83.5 127,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-114.3\">(None, 4, 100)</text>\n",
       "<polyline fill=\"none\" points=\"127,-106.5 225,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 2030830022600&#45;&gt;2030821837384 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2030830022600-&gt;2030821837384</title>\n",
       "<path d=\"M117,-166.366C117,-158.152 117,-148.658 117,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"120.5,-139.607 117,-129.607 113.5,-139.607 120.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030829363656 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2030829363656</title>\n",
       "<polygon fill=\"none\" points=\"15,-0.5 15,-46.5 219,-46.5 219,-0.5 15,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"40.5\" y=\"-19.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"66,-0.5 66,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"66,-23.5 122,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"122,-0.5 122,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-31.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"122,-23.5 219,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-8.3\">(None, 12425)</text>\n",
       "</g>\n",
       "<!-- 2030821837384&#45;&gt;2030829363656 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2030821837384-&gt;2030829363656</title>\n",
       "<path d=\"M117,-83.3664C117,-75.1516 117,-65.6579 117,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"120.5,-56.6068 117,-46.6068 113.5,-56.6069 120.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view model summary\n",
    "print(cbow.summary())\n",
    "\n",
    "# visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(cbow, show_shapes = True, show_layer_names = False,\n",
    "                rankdir = 'TB').create(prog = 'dot', format = 'svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalan\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100000 (context, word) pairs\n",
      "Processed 200000 (context, word) pairs\n",
      "Processed 300000 (context, word) pairs\n",
      "Processed 100000 (context, word) pairs\n",
      "Processed 200000 (context, word) pairs\n",
      "Processed 300000 (context, word) pairs\n",
      "Processed 100000 (context, word) pairs\n",
      "Processed 200000 (context, word) pairs\n",
      "Processed 300000 (context, word) pairs\n",
      "Epoch: 3 \tLoss: 5643893.039533119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 4):\n",
    "    loss = 0.0\n",
    "    i = 0\n",
    "    for x, y in generate_context_word_pairs(corpus = wids, window_size = window_size, vocab_size = vocab_size):\n",
    "        i += 1\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "        if i % 100000 == 0:\n",
    "            print('Processed {} (context, word) pairs'.format(i))\n",
    "            \n",
    "print('Epoch:', epoch, '\\tLoss:', loss)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12424, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unto</th>\n",
       "      <td>2.724105</td>\n",
       "      <td>2.542851</td>\n",
       "      <td>2.103535</td>\n",
       "      <td>2.018700</td>\n",
       "      <td>2.612822</td>\n",
       "      <td>2.160132</td>\n",
       "      <td>2.423507</td>\n",
       "      <td>2.218793</td>\n",
       "      <td>2.406465</td>\n",
       "      <td>2.013501</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.201379</td>\n",
       "      <td>2.364313</td>\n",
       "      <td>2.419034</td>\n",
       "      <td>-2.521388</td>\n",
       "      <td>-2.359560</td>\n",
       "      <td>-2.002176</td>\n",
       "      <td>2.389988</td>\n",
       "      <td>-2.484634</td>\n",
       "      <td>2.284837</td>\n",
       "      <td>2.769314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lord</th>\n",
       "      <td>1.916376</td>\n",
       "      <td>1.746418</td>\n",
       "      <td>2.353972</td>\n",
       "      <td>1.661239</td>\n",
       "      <td>2.130417</td>\n",
       "      <td>2.087705</td>\n",
       "      <td>2.139691</td>\n",
       "      <td>1.969467</td>\n",
       "      <td>1.973661</td>\n",
       "      <td>2.139762</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.200145</td>\n",
       "      <td>2.562431</td>\n",
       "      <td>2.245866</td>\n",
       "      <td>-2.099961</td>\n",
       "      <td>-2.402019</td>\n",
       "      <td>-2.091239</td>\n",
       "      <td>1.965681</td>\n",
       "      <td>-2.014546</td>\n",
       "      <td>2.152701</td>\n",
       "      <td>1.937042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thou</th>\n",
       "      <td>1.463074</td>\n",
       "      <td>1.288384</td>\n",
       "      <td>1.621969</td>\n",
       "      <td>1.382023</td>\n",
       "      <td>2.030033</td>\n",
       "      <td>2.365587</td>\n",
       "      <td>1.711562</td>\n",
       "      <td>2.331369</td>\n",
       "      <td>1.797766</td>\n",
       "      <td>1.544043</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.341234</td>\n",
       "      <td>2.204820</td>\n",
       "      <td>1.595766</td>\n",
       "      <td>-2.285288</td>\n",
       "      <td>-1.546738</td>\n",
       "      <td>-1.767799</td>\n",
       "      <td>1.104856</td>\n",
       "      <td>-1.518950</td>\n",
       "      <td>2.080063</td>\n",
       "      <td>1.744810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thy</th>\n",
       "      <td>2.176781</td>\n",
       "      <td>1.980541</td>\n",
       "      <td>1.784633</td>\n",
       "      <td>1.367590</td>\n",
       "      <td>1.690474</td>\n",
       "      <td>2.251390</td>\n",
       "      <td>1.911056</td>\n",
       "      <td>1.996371</td>\n",
       "      <td>2.150168</td>\n",
       "      <td>1.908925</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.738845</td>\n",
       "      <td>2.082861</td>\n",
       "      <td>1.729089</td>\n",
       "      <td>-2.008243</td>\n",
       "      <td>-1.738870</td>\n",
       "      <td>-1.667373</td>\n",
       "      <td>1.703266</td>\n",
       "      <td>-1.710272</td>\n",
       "      <td>1.768384</td>\n",
       "      <td>2.092158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>god</th>\n",
       "      <td>1.666263</td>\n",
       "      <td>1.813679</td>\n",
       "      <td>1.708619</td>\n",
       "      <td>1.277712</td>\n",
       "      <td>2.231061</td>\n",
       "      <td>2.161661</td>\n",
       "      <td>1.883334</td>\n",
       "      <td>2.236696</td>\n",
       "      <td>1.647958</td>\n",
       "      <td>1.934193</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.641103</td>\n",
       "      <td>1.733814</td>\n",
       "      <td>1.474875</td>\n",
       "      <td>-1.884667</td>\n",
       "      <td>-1.483192</td>\n",
       "      <td>-1.740509</td>\n",
       "      <td>1.602463</td>\n",
       "      <td>-1.778034</td>\n",
       "      <td>1.996362</td>\n",
       "      <td>2.188818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "unto  2.724105  2.542851  2.103535  2.018700  2.612822  2.160132  2.423507   \n",
       "lord  1.916376  1.746418  2.353972  1.661239  2.130417  2.087705  2.139691   \n",
       "thou  1.463074  1.288384  1.621969  1.382023  2.030033  2.365587  1.711562   \n",
       "thy   2.176781  1.980541  1.784633  1.367590  1.690474  2.251390  1.911056   \n",
       "god   1.666263  1.813679  1.708619  1.277712  2.231061  2.161661  1.883334   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "unto  2.218793  2.406465  2.013501  ... -2.201379  2.364313  2.419034   \n",
       "lord  1.969467  1.973661  2.139762  ... -2.200145  2.562431  2.245866   \n",
       "thou  2.331369  1.797766  1.544043  ... -1.341234  2.204820  1.595766   \n",
       "thy   1.996371  2.150168  1.908925  ... -1.738845  2.082861  1.729089   \n",
       "god   2.236696  1.647958  1.934193  ... -1.641103  1.733814  1.474875   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "unto -2.521388 -2.359560 -2.002176  2.389988 -2.484634  2.284837  2.769314  \n",
       "lord -2.099961 -2.402019 -2.091239  1.965681 -2.014546  2.152701  1.937042  \n",
       "thou -2.285288 -1.546738 -1.767799  1.104856 -1.518950  2.080063  1.744810  \n",
       "thy  -2.008243 -1.738870 -1.667373  1.703266 -1.710272  1.768384  2.092158  \n",
       "god  -1.884667 -1.483192 -1.740509  1.602463 -1.778034  1.996362  2.188818  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = cbow.get_weights()[0]\n",
    "weights = weights[1:]\n",
    "print(weights.shape)\n",
    "\n",
    "pd.DataFrame(weights, index = list(id2word.values())[1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12424, 12424)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'god': ['also', 'man', 'ye', 'lord', 'hath'],\n",
       " 'jesus': ['spirit', 'evil', 'gave', 'hands', 'heard'],\n",
       " 'noah': ['journeyed', 'burdens', 'floor', 'perished', 'filthy'],\n",
       " 'egypt': ['tree', 'babylon', 'mount', 'trees', 'though'],\n",
       " 'john': ['peter', 'entered', 'disciples', 'passed', 'received'],\n",
       " 'gospel': ['grace', 'hope', 'gentiles', 'hearts', 'saints'],\n",
       " 'moses': ['kept', 'wise', 'departed', 'throughout', 'sun'],\n",
       " 'famine': ['reproach', 'fallen', 'deep', 'slay', 'sleep']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# compute pairwise distance matrix\n",
    "distance_matrix = euclidean_distances(weights)\n",
    "print(distance_matrix.shape)\n",
    "\n",
    "#view contextuality similar words\n",
    "similar_words = {search_term : [id2word[idx] for idx in distance_matrix[word2id[search_term] - 1].argsort()[1 : 6] + 1]\n",
    "                for search_term in ['god', 'jesus', 'noah', 'egypt', 'john', 'gospel', 'moses', 'famine']}\n",
    "\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Skip Gram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the corpus vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 12425\n",
      "Vocabulary Sample: [('shall', 1), ('unto', 2), ('lord', 3), ('thou', 4), ('thy', 5), ('god', 6), ('ye', 7), ('said', 8), ('thee', 9), ('upon', 10)]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(norm_bible)\n",
    "\n",
    "word2id = tokenizer.word_index\n",
    "id2word = {v : k for k, v in word2id.items()}\n",
    "\n",
    "vocab_size = len(word2id) + 1\n",
    "embed_size = 100\n",
    "\n",
    "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_bible]\n",
    "print('Vocabulary Size:', vocab_size)\n",
    "print('Vocabulary Sample:', list(word2id.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(james (1154), badness (8603)) -> 0\n",
      "(king (13), bible (5766)) -> 1\n",
      "(bible (5766), king (13)) -> 1\n",
      "(king (13), jeremy (8122)) -> 0\n",
      "(king (13), abdeel (11001)) -> 0\n",
      "(james (1154), bible (5766)) -> 1\n",
      "(bible (5766), james (1154)) -> 1\n",
      "(james (1154), zachariah (5452)) -> 0\n",
      "(bible (5766), entappuah (9093)) -> 0\n",
      "(james (1154), king (13)) -> 1\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import skipgrams\n",
    "\n",
    "# generate skip-grams\n",
    "skip_grams = [skipgrams(wid, vocabulary_size = vocab_size, window_size = 10) for wid in wids]\n",
    "\n",
    "# view sample skip-grams\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(10):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "    id2word[pairs[i][0]], pairs[i][0],\n",
    "    id2word[pairs[i][1]], pairs[i][1],\n",
    "    labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the skip-gram model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedding_2_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3_input (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 100)       1242500     embedding_2_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 100)       1242500     embedding_3_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 100)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 100)          0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            201         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,485,201\n",
      "Trainable params: 2,485,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"516pt\" viewBox=\"0.00 0.00 494.00 387.00\" width=\"659pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1.33333 1.33333) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-383 490,-383 490,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2030439725512 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2030439725512</title>\n",
       "<polygon fill=\"none\" points=\"15.5,-332.5 15.5,-378.5 218.5,-378.5 218.5,-332.5 15.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"54\" y=\"-351.8\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"92.5,-332.5 92.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"92.5,-355.5 148.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"148.5,-332.5 148.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183.5\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"148.5,-355.5 218.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183.5\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 2030439723784 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2030439723784</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 234,-295.5 234,-249.5 0,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"40\" y=\"-268.8\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"80,-249.5 80,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"80,-272.5 136,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"136,-249.5 136,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"136,-272.5 234,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-257.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 2030439725512&#45;&gt;2030439723784 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2030439725512-&gt;2030439723784</title>\n",
       "<path d=\"M117,-332.366C117,-324.152 117,-314.658 117,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"120.5,-305.607 117,-295.607 113.5,-305.607 120.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030439817352 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2030439817352</title>\n",
       "<polygon fill=\"none\" points=\"267.5,-332.5 267.5,-378.5 470.5,-378.5 470.5,-332.5 267.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"306\" y=\"-351.8\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"344.5,-332.5 344.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"344.5,-355.5 400.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"400.5,-332.5 400.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"400.5,-355.5 470.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435.5\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 2030439773512 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2030439773512</title>\n",
       "<polygon fill=\"none\" points=\"252,-249.5 252,-295.5 486,-295.5 486,-249.5 252,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-268.8\">Embedding</text>\n",
       "<polyline fill=\"none\" points=\"332,-249.5 332,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"332,-272.5 388,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"388,-249.5 388,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"437\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"388,-272.5 486,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"437\" y=\"-257.3\">(None, 1, 100)</text>\n",
       "</g>\n",
       "<!-- 2030439817352&#45;&gt;2030439773512 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2030439817352-&gt;2030439773512</title>\n",
       "<path d=\"M369,-332.366C369,-324.152 369,-314.658 369,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"372.5,-305.607 369,-295.607 365.5,-305.607 372.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030439725000 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2030439725000</title>\n",
       "<polygon fill=\"none\" points=\"14.5,-166.5 14.5,-212.5 233.5,-212.5 233.5,-166.5 14.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"47\" y=\"-185.8\">Reshape</text>\n",
       "<polyline fill=\"none\" points=\"79.5,-166.5 79.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"79.5,-189.5 135.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-166.5 135.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-197.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"135.5,-189.5 233.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-174.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 2030439723784&#45;&gt;2030439725000 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2030439723784-&gt;2030439725000</title>\n",
       "<path d=\"M118.913,-249.366C119.623,-241.152 120.443,-231.658 121.215,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"124.715,-222.871 122.09,-212.607 117.741,-222.268 124.715,-222.871\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030439774536 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2030439774536</title>\n",
       "<polygon fill=\"none\" points=\"255.5,-166.5 255.5,-212.5 474.5,-212.5 474.5,-166.5 255.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-185.8\">Reshape</text>\n",
       "<polyline fill=\"none\" points=\"320.5,-166.5 320.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"320.5,-189.5 376.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"376.5,-166.5 376.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425.5\" y=\"-197.3\">(None, 1, 100)</text>\n",
       "<polyline fill=\"none\" points=\"376.5,-189.5 474.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425.5\" y=\"-174.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 2030439773512&#45;&gt;2030439774536 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2030439773512-&gt;2030439774536</title>\n",
       "<path d=\"M367.907,-249.366C367.501,-241.152 367.032,-231.658 366.591,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"370.081,-222.422 366.092,-212.607 363.089,-222.767 370.081,-222.422\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030439893576 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2030439893576</title>\n",
       "<polygon fill=\"none\" points=\"89.5,-83.5 89.5,-129.5 398.5,-129.5 398.5,-83.5 89.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132.5\" y=\"-102.8\">Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"175.5,-83.5 175.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"175.5,-106.5 231.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"231.5,-83.5 231.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315\" y=\"-114.3\">[(None, 100), (None, 100)]</text>\n",
       "<polyline fill=\"none\" points=\"231.5,-106.5 398.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"315\" y=\"-91.3\">(None, 200)</text>\n",
       "</g>\n",
       "<!-- 2030439725000&#45;&gt;2030439893576 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2030439725000-&gt;2030439893576</title>\n",
       "<path d=\"M156.791,-166.366C170.945,-156.812 187.662,-145.528 202.654,-135.409\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"204.919,-138.103 211.249,-129.607 201.002,-132.301 204.919,-138.103\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030439774536&#45;&gt;2030439893576 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2030439774536-&gt;2030439893576</title>\n",
       "<path d=\"M331.936,-166.366C317.664,-156.812 300.807,-145.528 285.691,-135.409\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"287.281,-132.261 277.024,-129.607 283.387,-138.078 287.281,-132.261\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2030439906184 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2030439906184</title>\n",
       "<polygon fill=\"none\" points=\"149,-0.5 149,-46.5 339,-46.5 339,-0.5 149,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-19.8\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"200,-0.5 200,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"200,-23.5 256,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"256,-0.5 256,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-31.3\">(None, 200)</text>\n",
       "<polyline fill=\"none\" points=\"256,-23.5 339,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 2030439893576&#45;&gt;2030439906184 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2030439893576-&gt;2030439906184</title>\n",
       "<path d=\"M244,-83.3664C244,-75.1516 244,-65.6579 244,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"247.5,-56.6068 244,-46.6068 240.5,-56.6069 247.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "from keras.layers.core import Dense, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "\n",
    "# build skip-gram architecture\n",
    "word_model = Sequential()\n",
    "word_model.add(Embedding(vocab_size, embed_size,\n",
    "                        embeddings_initializer = 'glorot_uniform',\n",
    "                        input_length = 1))\n",
    "word_model.add(Reshape((embed_size,)))\n",
    "\n",
    "context_model = Sequential()\n",
    "context_model.add(Embedding(vocab_size, embed_size,\n",
    "                           embeddings_initializer = 'glorot_uniform',\n",
    "                           input_length = 1))\n",
    "context_model.add(Reshape((embed_size,)))\n",
    "\n",
    "model = Concatenate(axis = 1)([word_model.output, context_model.output])\n",
    "model = Dense(1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid')(model)\n",
    "\n",
    "model = Model([word_model.input, context_model.input], model)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'rmsprop')\n",
    "\n",
    "# view model summary\n",
    "print(model.summary())\n",
    "\n",
    "# visualize model structure\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes = True, show_layer_names = False,\n",
    "                rankdir = 'TB').create(prog = 'dot', format = 'svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 (skip_first, skip_second, relevance) pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dalan\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
      "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 1 Loss: 3675.256048529409\n",
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
      "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 2 Loss: 3205.4641918134876\n",
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
      "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
      "Epoch: 3 Loss: 3121.5985806973185\n",
      "Processed 0 (skip_first, skip_second, relevance) pairs\n",
      "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
      "Processed 20000 (skip_first, skip_second, relevance) pairs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b62564b48f1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Processed {} (skip_first, skip_second, relevance) pairs'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Packages\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3624\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3625\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3627\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Packages\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 4):\n",
    "    loss = 0\n",
    "    for i, elem in enumerate(skip_grams):\n",
    "        pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype = 'int32')\n",
    "        pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype = 'int32')\n",
    "        labels = np.array(elem[1], dtype = 'int32')\n",
    "        X = [pair_first_elem, pair_second_elem]\n",
    "        Y = labels\n",
    "        if i % 10000 == 0:\n",
    "            print('Processed {} (skip_first, skip_second, relevance) pairs'.format(i))\n",
    "        loss += model.train_on_batch(X, Y)\n",
    "        \n",
    "    print('Epoch:', epoch, 'Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_layer = model.layers[0]\n",
    "word_model = merge_layer.layers[0]\n",
    "word_embed_layer = word_model.layers[0]\n",
    "weights = word_embed_layer.get_weights()[0][1:]\n",
    "\n",
    "print(weights.shape)\n",
    "pd.DataFrame(weights, index = id2word.values()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "distance_matrix = euclidean_distances(weights)\n",
    "print(distance_matrix.shape)\n",
    "\n",
    "similar_words = {search_term : [id2word[idx] for idx in distance_matrix[word2id[search_term] - 1].argsort()[1 : 6] + 1]\n",
    "                for search_term in ['god', 'jesus', 'noah', 'egypt', 'john', 'gospel', 'moses', 'famine']}\n",
    "\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "words = sum([[k] + v for k, v in similar_words.items()], [])\n",
    "words_ids = [word2id[w] for w in words]\n",
    "word_vectors = np.array(weights[idx] for idx in words_ids)\n",
    "print('Total words:', len(words), '\\tWord Embedding shapes:', word_vectors.shape)\n",
    "\n",
    "tsne = TSNE(n_components = 2, random_state = 0, n_iter = 10000, perplexity = 3)\n",
    "np.set_printoptions(supress = True)\n",
    "T = tsne.fit_transform(word_vectors)\n",
    "labels = words\n",
    "\n",
    "plt.figure(figsize = (14, 8))\n",
    "plt.scatter(T[:, 0], T[:, 1], c = 'steelblue', esgecolors = 'k')\n",
    "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
    "    plt.annotate(label, xy = (x + 1, y + 1), xytext = (0, 0), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
